---
title: "classify_run1_coi"
author: "Eily Allan - modified from Erin D'Agnese and Ramon Gallego"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: html_document
params: 
  folder:
    value: /Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_EA/Output/classification_output/run1_20211117/COI
  Hash_key:
    value: /Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_EA/Output/dada2_output/run1_20211117/COI/hash_key.csv
  ASVs: 
    value: /Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_EA/Output/dada2_output/run1_20211117/COI/ASV_table.csv
---

Last updated: 2/2/22

# Overview

This code is meant to take output from dada2 and assign taxonomy. This is adapted from Ramon Gallego's "insect.all.Rmd" script found here (https://github.com/ramongallego/eDNA.and.Ocean.Acidification.Gallego.et.al.2020/tree/master/Scripts). 

The general overview is that ASVs from dada2 will be read in and classified via insect, using the classifier publicly available from the creators of insect (found here - https://cran.r-project.org/web/packages/insect/vignettes/insect-vignette.html). We will save the classifications for future runs (so we don't need to keep classifying the same hash). We will save two versions - the first if a hash is given any taxonomic rank by insect, and the second if a hash is given a "good" classification by insect. We have different thresholds for what is a "good" classification for COI and 12S so we want to set different parameters - we want 12S to get all the way to species level but with COI we expect less resolved taxonomic resolution so we will classify anything to family level as "good".

After we save these from run 1, in future runs, we will first check to see if the hashes were already classified here and then we will only classify *new* hashes. Then we will add those new ones to our list of previously classified for the next run, and so on...
 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = params$folder)
```

# Set up

## Load libraries and set file paths, etc.

```{r load libraries}
library (tidyverse)
library (insect)
library (seqinr)
library (here)
library(taxonomizr)

run <- "1"
marker <- "COI"

# note that the classifier is stored LOCALLY so need to change file path 
classifier <- "/Users/elizabethandruszkiewicz/GoogleDrive/UW/GitHub/NextGenNEPA_LOCAL/Input/classifiers/classifier_COI_v5.rds"

run_output_folder <- paste0(here("Output","classification_output"),"/run",params$run) 
dir.create(path = run_output_folder)
run_marker_output_folder <- paste0(run_output_folder,"/",params$marker)
dir.create(path = run_marker_output_folder)
```


# Step 0: Read in files.

Read in ASV table and hash key for run 1 and the classifier.

```{r read in hashes, asv table, and tree}

Hash_key <- read_csv(params$Hash_key)
Hash <- Hash_key %>%
  select(Hash, Sequence) %>% distinct()

ALL.ASVs <- read_csv(params$ASVs)

tree <- read_rds(classifier)

```

## RC Run 1 of COI

*IMPORTANT*: Only for COI, we need to RC the ones that we put primers on backwards (facepalm). In this case, all of run 1 is backwards so we need this step - in the next scripts, runs 2/3/4 have some but not all backwards. Any run after that should always be forwards.  

```{r rc coi hashes}

## RUN 1 COI IS ALL BACKWARDS
#reverse complement the representative sequence for each hash
rc_seq <- vector(length = dim(Hash_key)[1])
# this is ridiculous and shouldn't be for loop but wtf i can't get it to work
for (i in 1:dim(Hash_key)[1]) {
  rc_seq[i] = rc(Hash_key[i,2])
}
Hash_key$Sequence <- rc_seq
Hash <- Hash_key %>%
  select(Hash, Sequence) %>% distinct()
```


# Step 1: Now classify all ASVs with the insect classifier. And then add the new classifications to make a new "previous effort".

## Classify 

Note that the classifier is maintained by insect. We are using version 5, which was last updated on 20181124. Check here to see if there is a newer version: https://cran.r-project.org/web/packages/insect/vignettes/insect-vignette.html

```{r classify}

# reformat to be as insect likes it
all.hashes.insect <- char2dna(Hash$Sequence)
names (all.hashes.insect) <- Hash$Hash
# check it
all.hashes.insect

# do the classification! this takes a while
clasif.hashes <- classify (x = all.hashes.insect, tree = tree, cores = 4)

# rename columns to be useful
names(clasif.hashes) <- c('representative', 'taxID', 'taxon', 'rank', 'score', 'kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species')

```

## Check them out
Now that we have classifications, let's start looking at the results and see how well the classifier did.

```{r check out results and manipulate a little}

# look at family/genus/species classifications
clasif.hashes %>% 
  unite (family, genus, species, sep = "|", col = "taxa")

# see how many were not assigned a rank
clasif.hashes %>% dplyr::count (rank) %>% arrange(desc(n))

# How many have a valid family but no phylum info
clasif.hashes %>% 
  filter(family!= "" & phylum == "") %>% 
  distinct(class) 

# Add new phylum info
clasif.hashes %>% 
  mutate(phylum = case_when(phylum != "" ~ phylum,
                            TRUE   ~ class))

```

## Save them all

OK. So now let's save the classification object as an RDS and CSV. This will be the base for classifying all other runs. In future runs, the first thing we will do is check to see if the hash has already been classified. 

We are actually going to save two versions of this - one that is all hashes that are classified to anything (to get the most information possible) - but then also just "good" classifications (so that we don't save a not great classification and then never go back and try to classify it again with insect or BLAST). 

```{r save all classifications}

# first, let's save it in a subfolder of Output/classification_output/ and the run - so we know what was classified only from run 1
# that is our "run_marker_output_folder" file path that we defined above
# here we will save it as both an rds and a csv 
saveRDS(clasif.hashes, paste0(run_marker_output_folder,"/new.hashes.annotated.rds"))
clasif.hashes <- readRDS(paste0(run_marker_output_folder,"/new.hashes.annotated.rds"))
write.csv(clasif.hashes, paste0(run_marker_output_folder,"/new.hashes.annotated.csv"))

# also write them as a tax table in the same place
source(here("functions", "tax.table.R"))
taxtable <- tax.table(clasif.hashes)
write.csv(taxtable,file=paste0(run_marker_output_folder,"/tax.table.csv"))

# now, let's also save a copy of them in the general Output/classification_output folder that we can re-write over and over again as we add new classifications each time that we add another run 

# so here we are going to change the file path - and the file name to say "all.previous.hashes" - and let's also add the date on the end of the file name so we know when it was last updated - this will be slightly annoying later when we have to change the file name when we read in the classifications, but probably worth it so we keep track of things
# save it again as an rds and then also as a csv - and tax table
saveRDS(clasif.hashes, file=paste0(here("Output","classification_output"),"/",format(Sys.Date(), "%Y%m%d"), ".", params$marker,".all.previous.hashes.annotated.rds"))
clasif.hashes <- readRDS(file=paste0(here("Output","classification_output"),"/",format(Sys.Date(), "%Y%m%d"), ".", params$marker,".all.previous.hashes.annotated.rds"))
write.csv(clasif.hashes, file=paste0(here("Output","classification_output"),"/",format(Sys.Date(), "%Y%m%d"), ".", params$marker,".all.previous.hashes.annotated.csv"))
write.csv(taxtable,file=paste0(here("Output","classification_output"),"/",format(Sys.Date(), "%Y%m%d"), ".", params$marker,"previous.tax.table.csv"))

```

## Save just the good ones 

What we call "good" is going to be different for COI vs. 12S. For 12S, we really want to get to species level so we will only call species level IDs "good". For COI, we don't expect to get to species level for most things because the marker is so general/universal. So... let's start with calling anything to family level "good" and then go from there. 

```{r save only good classifications}

# but let's only save the "good ones" (FAMILY  for COI) to use as a previous effort 
good.clasif.hashes <- clasif.hashes %>% filter(rank == "family")

# first, let's save it in a subfolder of Output/classification_output/ and the run - so we know what was classified only from run 1
# that is our "run_marker_output_folder" file path that we defined above
# here we will save it as both an rds and a csv 
saveRDS(good.clasif.hashes, paste0(run_marker_output_folder,"/new.good.hashes.annotated.rds"))
clasif.hashes <- readRDS(paste0(run_marker_output_folder,"/new.good.hashes.annotated.rds"))
write.csv(clasif.hashes, paste0(run_marker_output_folder,"/new.good.hashes.annotated.csv"))

# also write them as a tax table in the same place
source(here("functions", "tax.table.R"))
taxtable <- tax.table(good.clasif.hashes)
write.csv(taxtable,file=paste0(run_marker_output_folder,"/good.tax.table.csv"))

# now, let's also save a copy of them in the general Output/classification_output folder that we can re-write over and over again as we add new classifications each time that we add another run 

# so here we are going to change the file path - and the file name to say "all.previous.hashes" - and let's also add the date on the end of the file name so we know when it was last updated - this will be slightly annoying later when we have to change the file name when we read in the classifications, but probably worth it so we keep track of things
# save it again as an rds and then also as a csv - and tax table
saveRDS(clasif.hashes, file=paste0(here("Output","classification_output"),"/",format(Sys.Date(), "%Y%m%d"), ".", params$marker,".all.good.previous.hashes.annotated.rds"))
clasif.hashes <- readRDS(file=paste0(here("Output","classification_output"),"/",format(Sys.Date(), "%Y%m%d"), ".", params$marker,".all.good.previous.hashes.annotated.rds"))
write.csv(clasif.hashes, file=paste0(here("Output","classification_output"),"/",format(Sys.Date(), "%Y%m%d"), ".", params$marker,".all.good.previous.hashes.annotated.csv"))
write.csv(taxtable,file=paste0(here("Output","classification_output"),"/",format(Sys.Date(), "%Y%m%d"), ".", params$marker,"previous.good.tax.table.csv"))

```

Let's stop here for now - later, we can go back and blast any "not good" classifications to see how much more information we get. But for now, let's just get the pipeline up and running and get the majority of things classified. Later we can (hopefully) easily add in a step where we take anything that is not yet classified and BLAST it to squeeze every bit of information we can out of the data. 

We could even do this after we classify ALL the runs and then just have one large blast script with all ASVs that don't get annotated to only BLAST once instead of 10+ times. 
